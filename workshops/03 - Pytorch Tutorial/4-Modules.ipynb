{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this notebook about?\n",
    "\n",
    "In this notebook, we will learning about PyTorch modules and the great functionalities they provide. Later on, we'll create a small a multilayer perceptron to perform image classification on MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 18.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# execute only if you're using Google Colab\n",
    "!wget -q https://raw.githubusercontent.com/ahug/amld-pytorch-workshop/master/binder/requirements.txt -O requirements.txt\n",
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 0.4.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, there are many predefined layer like Convolutions, RNN, Pooling, Linear, etc.\n",
    "\n",
    "These functions are wrapped in **modules** and inherit from the **torch.nn.Module** base class.\n",
    "\n",
    "When designing a custom model in PyTorch, you should follow this strategy and derive your class from **torch.nn.Module**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base class for all neural network modules.\n",
      "\n",
      "    Your models should also subclass this class.\n",
      "\n",
      "    Modules can also contain other Modules, allowing to nest them in\n",
      "    a tree structure. You can assign the submodules as regular attributes::\n",
      "\n",
      "        import torch.nn as nn\n",
      "        import torch.nn.functional as F\n",
      "\n",
      "        class Model(nn.Module):\n",
      "            def __init__(self):\n",
      "                super(Model, self).__init__()\n",
      "                self.conv1 = nn.Conv2d(1, 20, 5)\n",
      "                self.conv2 = nn.Conv2d(20, 20, 5)\n",
      "\n",
      "            def forward(self, x):\n",
      "               x = F.relu(self.conv1(x))\n",
      "               return F.relu(self.conv2(x))\n",
      "\n",
      "    Submodules assigned in this way will be registered, and will have their\n",
      "    parameters converted too when you call `.cuda()`, etc.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.Module.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules are doing a lot of \"magic\" under the hood.\n",
    "\n",
    "- It registers all the parameters of your model.\n",
    "- It simplifies the saving/loading of your model.\n",
    "- It provides helper functions to reset/freeze/update the gradients.\n",
    "- It provides helper functions to put all parameters on a device (GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a torch.nn.Parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Parameter is a Tensor with `requires_grad` to `True` by default, and which is automatically added to the list of parameters when used within a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the documentation ([torch.nn.Parameter](https://pytorch.org/docs/stable/_modules/torch/nn/parameter.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A kind of Tensor that is to be considered a module parameter.\n",
      "\n",
      "    Parameters are :class:`~torch.Tensor` subclasses, that have a\n",
      "    very special property when used with :class:`Module` s - when they're\n",
      "    assigned as Module attributes they are automatically added to the list of\n",
      "    its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.\n",
      "    Assigning a Tensor doesn't have such effect. This is because one might\n",
      "    want to cache some temporary state, like last hidden state of the RNN, in\n",
      "    the model. If there was no such class as :class:`Parameter`, these\n",
      "    temporaries would get registered too.\n",
      "\n",
      "    Arguments:\n",
      "        data (Tensor): parameter tensor.\n",
      "        requires_grad (bool, optional): if the parameter requires gradient. See\n",
      "            :ref:`excluding-subgraphs` for more details. Default: `True`\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.Parameter.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.0236,  0.0067,  0.0104],\n",
      "         [ 0.0949,  0.0441, -0.0942],\n",
      "         [ 0.0506, -0.1818, -0.0155],\n",
      "         [-0.0487,  0.0186, -0.0384],\n",
      "         [ 0.1200,  0.0932, -0.0640],\n",
      "         [ 0.0726,  0.0050,  0.0149],\n",
      "         [-0.1086,  0.0171,  0.0924],\n",
      "         [ 0.0247,  0.0874,  0.1692],\n",
      "         [-0.1381,  0.1730, -0.0163],\n",
      "         [-0.1236,  0.0842,  0.1532]],\n",
      "\n",
      "        [[ 0.0724,  0.1428, -0.0615],\n",
      "         [ 0.1243,  0.1041,  0.1055],\n",
      "         [ 0.1430, -0.1725, -0.0646],\n",
      "         [-0.0439,  0.1180, -0.0785],\n",
      "         [ 0.0135,  0.1214,  0.1648],\n",
      "         [-0.0340,  0.1622,  0.1039],\n",
      "         [ 0.0864,  0.0921,  0.0904],\n",
      "         [-0.0386, -0.1658,  0.1679],\n",
      "         [ 0.0398, -0.0278,  0.1036],\n",
      "         [-0.0038, -0.0723,  0.0673]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "mod = nn.Conv1d(10, 2, 3)\n",
    "print(mod.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very simple example of a module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A module has to implemented the `forward` function which is executed during the forward pass.\n",
    "\n",
    "All your model's submodules and parameters should be instantiated in the `__init__` function. This way PyTorch know that they exist and registers them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple module\n",
    "class MySuperSimpleModule(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MySuperSimpleModule, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the print function to list a model's submodules/parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySuperSimpleModule(\n",
      "  (linear): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MySuperSimpleModule(input_size=20, num_classes=5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use **`model.parameters()`** to get the list of parameters of your model automatically inferred by PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear.weight :\n",
      " Parameter containing:\n",
      "tensor([[ 0.2004,  0.0563,  0.1745,  0.0697,  0.0947,  0.1832, -0.0452, -0.0017,\n",
      "         -0.1560,  0.1838,  0.1933, -0.1326,  0.1312,  0.1696, -0.1486,  0.1382,\n",
      "         -0.2122,  0.0248,  0.0662,  0.0797],\n",
      "        [ 0.1165,  0.0055, -0.0324,  0.1490,  0.1233, -0.0380,  0.0742,  0.1925,\n",
      "         -0.0545,  0.0063,  0.0238, -0.1700, -0.2219,  0.0376, -0.1953, -0.0789,\n",
      "          0.1992,  0.1166,  0.0563,  0.0777],\n",
      "        [-0.1723,  0.0720,  0.2057,  0.1241, -0.0255, -0.0383, -0.2165,  0.1208,\n",
      "          0.1533, -0.2165,  0.1670, -0.0550, -0.0251, -0.0367, -0.0623, -0.1304,\n",
      "         -0.1005,  0.0034, -0.0318, -0.0436],\n",
      "        [ 0.2082, -0.1200,  0.1100,  0.1590, -0.0658, -0.0524, -0.1643,  0.2146,\n",
      "         -0.0387,  0.1262,  0.1354,  0.1369, -0.0160,  0.1223,  0.0821,  0.0104,\n",
      "         -0.2074, -0.0318, -0.0194,  0.0273],\n",
      "        [-0.0614, -0.1570,  0.1563, -0.1889,  0.0329, -0.0987, -0.1242, -0.0954,\n",
      "         -0.1158,  0.0420, -0.0477, -0.1129, -0.1437, -0.0431,  0.1707,  0.0969,\n",
      "         -0.0437, -0.2002,  0.0770, -0.0186]], requires_grad=True)\n",
      "linear.bias :\n",
      " Parameter containing:\n",
      "tensor([0.1767, 0.1742, 0.1039, 0.1311, 0.1330], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():  # Here we use a sligtly different version of the parameters() function\n",
    "    print(name, \":\\n\", p)                 # which also returns the parameter name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple network for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![We need to go depper](figures/deeper.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a more complicated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a simple multilayer perceptron with two hidden layers and the following structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/ledell/sldm4-h2o/master/mlp_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input-size: *input_size*\n",
    "- 1st hidden layer: 75\n",
    "- 2nd hidden layer: 50\n",
    "- Output layer: *num_classes*\n",
    "\n",
    "Additionally, we use `ReLU`s as activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need some PyTorch NN modules - Find them in the [PyTorch doc](https://pytorch.org/docs/master/nn.html) (especially nn.Linear)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F  # provides some helper functions like Relu's, Sigmoids, Tanh, etc.\n",
    "\n",
    "\n",
    "class MyMultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MyMultilayerPerceptron, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_1 = nn.Linear(input_size, 75)\n",
    "        self.linear_2 = nn.Linear(75, 50)\n",
    "        self.linear_3 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.linear_1(x))\n",
    "        out = F.relu(self.linear_2(out))\n",
    "        out = self.linear_3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print your network's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyMultilayerPerceptron(\n",
      "  (linear_1): Linear(in_features=784, out_features=75, bias=True)\n",
      "  (linear_2): Linear(in_features=75, out_features=50, bias=True)\n",
      "  (linear_3): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyMultilayerPerceptron(784, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed an input to your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0186,  0.0303,  0.1133,  0.0693,  0.1682, -0.0290,  0.3097,  0.2018,\n",
       "        -0.1038, -0.1881], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(16, 784)  # the first dimension is reserved for the 'batch_size'\n",
    "out = model(x)  # equivalent to model.forward(x)\n",
    "out[0, :] ## looking at the output of 1 batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the functions to train a model follow a similar pattern in PyTorch.\n",
    "In most of the cases in consists of the following steps:\n",
    "- Loop over data (in batches)\n",
    "- Forward pass\n",
    "- Zero gradients!\n",
    "- Backward pass\n",
    "- Parameter update (Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, data_loader, device):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define the Loss function and Optimizer that you want to use\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # NOTE: model.parameters()\n",
    "    \n",
    "    # Outter training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Inner training loop\n",
    "        cum_loss = 0\n",
    "        for (inputs, labels) in data_loader:\n",
    "            # Prepare inputs and labels for processing by the model (e.g. reshape, move to device, ...)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # original shape is [batch_size, 28, 28] because it's an image of size 28x28\n",
    "            inputs = inputs.view(-1, 28*28)\n",
    "\n",
    "            # Do Forward -> Loss Computation -> Backward -> Optimization\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            cum_loss += loss.item()\n",
    "        print(\"Epoch %d, Loss=%.4f\" % (epoch+1, cum_loss/len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- we can use the `.to` function on the model directly. Indeed, since PyTorch knows all the model parameters, it can put all the parameters on the correct device.\n",
    "- we use `model.parameters()` to get all the parameters of the model and we can instantiate an optimizer that will optimize these parameters `torch.optim.SGD(model.parameters())`.\n",
    "- to apply the forward function of the module, we write `model(input)`. In most cases, `model.forward(inputs)` would also work, but there is a slight difference : PyTorch allows you to register hook functions for a model that are automatically called when you do a forward pass on your model. Using `model(input)` will call these hooks and then call the forward function, while using `model.forward(inputs)` will just silently ignore them.\n",
    "\n",
    "Do you feel the power of Modules ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch comes with a lot of predefined loss functions :\n",
    "- L1Loss\n",
    "- MSELoss\n",
    "- CrossEntropyLoss\n",
    "- NLLLoss\n",
    "- PoissonNLLLoss\n",
    "- KLDivLoss\n",
    "- BCELoss\n",
    "- MarginRankingLoss\n",
    "- HingeEmbeddingLoss\n",
    "- MultiLabelMarginLoss\n",
    "- CosineEmbeddingLoss\n",
    "- TripletMarginLoss\n",
    "- ...\n",
    "\n",
    "Check out the [PyTorch Documentation](https://pytorch.org/docs/master/nn.html#loss-functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train our model on the MNIST digit classification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST](figures/mnist.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to load the training and test images. MNIST is a widely used dataset, therefore the torchvision package provides simple functionalities to load images from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Dataset Loader (Input Batcher)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the actual training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=0.3895\n",
      "Epoch 2, Loss=0.1762\n",
      "Epoch 3, Loss=0.1273\n",
      "Epoch 4, Loss=0.0979\n",
      "Epoch 5, Loss=0.0791\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MyMultilayerPerceptron(input_size=784, num_classes=10)\n",
    "num_epochs = 5\n",
    "\n",
    "train(model, num_epochs, train_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we now assess the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function loops over another `data_loader` (usually containing test/validation data) and computes the model's accuracy on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, data_loader, device):\n",
    "    with torch.no_grad(): # during model evaluation, we don't need the autograd mechanism (speeds things up)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)     \n",
    "            inputs = inputs.view(-1, 28*28)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            correct += (predicted.cpu() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "    acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9717"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, test_loader, device)  # look at: accuracy(model, train_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We get an accuracy of ~97.9%, can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we now store our trained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type MyMultilayerPerceptron. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"my_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_loaded = torch.load(\"my_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([-0.0806, -0.0041,  0.0795, -0.2120, -0.0777,  0.2158,  0.0327,  0.0568,\n",
       "         -0.1043,  0.0588], requires_grad=True), Parameter containing:\n",
       " tensor([-0.0806, -0.0041,  0.0795, -0.2120, -0.0777,  0.2158,  0.0327,  0.0568,\n",
       "         -0.1043,  0.0588], requires_grad=True))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear_3.bias, my_model_loaded.linear_3.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't forget to download the notebook, otherwise your changes may be lost!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Download the notebook](figures/notebook-download.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
