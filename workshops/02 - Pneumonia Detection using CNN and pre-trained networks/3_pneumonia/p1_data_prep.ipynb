{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with publicly available data at [Mendeley Data - Chest X-Ray Images](https://data.mendeley.com/datasets/rscbjbr9sj/2)\n",
    "\n",
    "Let's download and unzip the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data/chest_xray'):\n",
    "    os.makedirs('./data', exist_ok=True)\n",
    "    urllib.request.urlretrieve(\"https://s3.eu-central-1.amazonaws.com/public.unit8.co/data/chest_xray.tar.gz\", \"data/chest_xray.tar.gz\")\n",
    "    tar = tarfile.open(\"data/chest_xray.tar.gz\")\n",
    "    tar.extractall(path='./data/')\n",
    "    os.remove('data/chest_xray.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is organized into 3 folders (**train**, **test**, **val**) and contains subfolders for each image category (Pneumonia/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (**NORMAL** / **PNEUMONIA**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('./data/chest_xray/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chest X-ray images were selected from cohorts of pediatric patients of one to five years old from. All chest X-ray imaging was performed as part of patients’ routine clinical care.\n",
    "\n",
    "For the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display a few images and try to see differences between two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_normal = plt.imread('./data/chest_xray/train/NORMAL/IM-0131-0001.jpeg')\n",
    "img_penumonia_bacteria = plt.imread('./data/chest_xray/train/PNEUMONIA/person1017_bacteria_2948.jpeg')\n",
    "img_penumonia_virus = plt.imread('./data/chest_xray/train/PNEUMONIA/person1021_virus_1711.jpeg')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1,3,1).set_title('NORMAL')\n",
    "plt.imshow(img_normal, cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,2).set_title('PNEUMONIA')\n",
    "plt.imshow(img_penumonia_bacteria, cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,3).set_title('PNEUMONIA')\n",
    "plt.imshow(img_penumonia_virus, cmap='gray')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrative examples of Chest X-Rays in patients with pneumonia\n",
    "\n",
    "- normal chest X-ray (left) depicts clear lungs without any areas of abnormal opacification in the image\n",
    "- bacterial pneumonia (middle) typically exhibits a focal lobar consolidation, in this case in the left lobe\n",
    "- viral pneumonia (right) manifests with a more diffuse ‘‘interstitial’’ pattern in both lungs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to write a function that maps image path to class:\n",
    "- 0 = NORMAL\n",
    "- 1 = PNEUMONIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_files(folder):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            if folderName in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif folderName in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "                continue # we do not investigate other dirs\n",
    "            for image_filename in os.listdir(folder + folderName):\n",
    "                img_path = folder + folderName + '/' + image_filename\n",
    "                if img_path is not None and str.endswith(img_path, 'jpeg'):\n",
    "                    x.append(img_path)\n",
    "                    y.append(label)\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_labeled_files('./data/chest_xray/train/')\n",
    "\n",
    "list(zip(x, y))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start working with the images need to peform a little of preprocessing, i.e. \n",
    "- read the image into an array (3 color channels)\n",
    "- resize the image to 150px x 150px \n",
    "- one hot encode image lables\n",
    "\n",
    "We are composing the transformations using Tensorflow data pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "\n",
    "# This function takes image paths as arguments and reads corresponding images\n",
    "def input_parser(img_path, label):\n",
    "    # convert the label to one-hot encoding\n",
    "    one_hot = tf.one_hot(label, NUM_CLASSES)\n",
    "    # read the img from file and decode it using tf\n",
    "    img_file = tf.read_file(img_path)\n",
    "    img_decoded = tf.image.decode_jpeg(img_file, channels=3, name=\"decoded_images\")\n",
    "    return img_decoded, one_hot\n",
    "\n",
    "# This function takes image and resizes it to smaller format (150x150)\n",
    "def image_resize(images, labels):\n",
    "    # Be very careful with resizing images like this and make sure to read the doc!\n",
    "    # Otherwise, bad things can happen - https://hackernoon.com/how-tensorflows-tf-image-resize-stole-60-days-of-my-life-aba5eb093f35\n",
    "    resized_image = tf.image.resize_images(images, (150, 150), align_corners=True)\n",
    "    resized_image_asint = tf.cast(resized_image, tf.int32)\n",
    "    return resized_image_asint, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution plan is defined here.\n",
    "# Since it uses lazy evaluation, the images will not be read after calling build_pipeline_plan()\n",
    "# We need to use iterator defined here in tf context\n",
    "def build_pipeline_plan(img_paths, labels, batch_size):\n",
    "\n",
    "    # We build a tensor of image paths and labels\n",
    "    tr_data = Dataset.from_tensor_slices((img_paths, labels))\n",
    "    # First step of input pipeline - read images in paths as jpegs\n",
    "    tr_data_imgs = tr_data.map(input_parser)\n",
    "    # Apply resize to each image in the pipeline\n",
    "    tr_data_imgs = tr_data_imgs.map(image_resize)\n",
    "    # Gives us opportuinty to batch images into small groups\n",
    "    tr_dataset = tr_data_imgs.batch(batch_size)\n",
    "    # create TensorFlow Iterator object directly from input pipeline\n",
    "    iterator = tr_dataset.make_one_shot_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    return next_element\n",
    "\n",
    "# Function to execute defined pipeline in Tensorflow session\n",
    "def process_pipeline(next_element):\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        # get each element of the training dataset until the end is reached\n",
    "        # in our case only one iteration since we read everything as 1 batch\n",
    "        # can be multiple iterations if we decrease BATCH_SIZE to eg. 10\n",
    "        images = []\n",
    "        labels_hot = []\n",
    "        while True:\n",
    "            try:\n",
    "                elem = sess.run(next_element)\n",
    "                images = elem[0]\n",
    "                labels_hot = elem[1]\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"Finished reading the dataset\")\n",
    "                return images, labels_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, batch_size):\n",
    "    tf.reset_default_graph()\n",
    "    files, labels = get_labeled_files(path)\n",
    "    p = tf.constant(files, name=\"train_imgs\")\n",
    "    l = tf.constant(labels, name=\"train_labels\")\n",
    "    \n",
    "    next_element = build_pipeline_plan(p, l, batch_size=batch_size)\n",
    "    imgs, labels = process_pipeline(next_element)\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to load load the data (train, test and validation) into separate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_dataset(\"./data/chest_xray/train/\", 6000)\n",
    "x_test, y_test = load_dataset(\"./data/chest_xray/test/\", 6000)\n",
    "x_val, y_val = load_dataset(\"./data/chest_xray/val/\", 6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape of the data structures. All images are 150px x 150px with three color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable is One-hot encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.countplot(np.argmax(y_train, axis=1)).set_title('TRAIN')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.countplot(np.argmax(y_test, axis=1)).set_title('TEST')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.countplot(np.argmax(y_val, axis=1)).set_title('VALIDATION')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our datasets are **imbalanced**. We see more examples with **PNEUMONIA** x-ray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 normal, 2 sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
